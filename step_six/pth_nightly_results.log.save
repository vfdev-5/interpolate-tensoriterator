
__version__ = 1.8.0.dev20210208+cu110
debug = False
cuda = 11.0
git_version = 71e7186e5dcb44fb9e9bacf841a11f3cfd3215f8
hip = None


Torch config: PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) Math Kernel Library Version 2020.0.0 Product Build 20191122 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v1.7.0 (Git Hash 7aed236906b1f7a05c0917e5257a1af05e9ff683)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.0
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80
  - CuDNN 8.0.5
  - Magma 2.5.2
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.0, CUDNN_VERSION=8.0.5, CXX_COMPILER=/opt/rh/devtoolset-7/root/usr/bin/c++, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.8.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, 

Num threads: 6


---- Benchmark 2D ----

Input tensor: [1, 3, 320, 320]
Input is_contiguous memory_format torch.channels_last: False
Input is_contiguous : True

- Bench upsample_bilinear2d (20000 rounds) - downsampling to 256x256
Elapsed time (ms): 0.32613341808319096

- Bench upsample_bilinear2d (20000 rounds) - upsampling to 512x512
Elapsed time (ms): 1.2854440212249756

Input tensor: [1, 3, 320, 320]
Input is_contiguous memory_format torch.channels_last: False
Input is_contiguous : False

- Bench upsample_bilinear2d (20000 rounds) - downsampling to 256x256
Elapsed time (ms): 0.3488125801086426

- Bench upsample_bilinear2d (20000 rounds) - upsampling to 512x512
Elapsed time (ms): 1.3063045620918274

Input tensor: [1, 3, 320, 320]
Input is_contiguous memory_format torch.channels_last: True
Input is_contiguous : False

- Bench upsample_bilinear2d (20000 rounds) - downsampling to 256x256
Elapsed time (ms): 1.0897232055664063

- Bench upsample_bilinear2d (20000 rounds) - upsampling to 512x512
Elapsed time (ms): 4.250537252426147

1 - Test size as in https://github.com/mingfeima/op_bench-py

Input tensor: [32, 128, 64, 64]
Input is_contiguous memory_format torch.channels_last: True
Input is_contiguous : False

- Bench upsample_bilinear2d (2000 rounds) - downsampling to 32x32
Elapsed time (ms): 2.29608154296875

- Bench upsample_bilinear2d (2000 rounds) - upsampling to 128x128
Elapsed time (ms): 35.93837213516235

2 - Test size as in https://github.com/mingfeima/op_bench-py

Input tensor: [32, 128, 64, 64]
Input is_contiguous memory_format torch.channels_last: False
Input is_contiguous : True

- Bench upsample_bilinear2d (2000 rounds) - downsampling to 32x32
Elapsed time (ms): 3.6901973485946655

- Bench upsample_bilinear2d (2000 rounds) - upsampling to 128x128
Elapsed time (ms): 86.7835146188736

Input tensor: [1, 3, 500, 500]
Input is_contiguous memory_format torch.channels_last: False
Input is_contiguous : True

- Bench upsample_bilinear2d (20000 rounds) - downsampling to 256x256
Elapsed time (ms): 0.3266031742095947

- Bench upsample_bilinear2d (20000 rounds) - upsampling to 800x800
Elapsed time (ms): 3.1867913961410523

Input tensor: [1, 3, 500, 500]
Input is_contiguous memory_format torch.channels_last: False
Input is_contiguous : False

- Bench upsample_bilinear2d (20000 rounds) - downsampling to 256x256
Elapsed time (ms): 0.37711663246154786

- Bench upsample_bilinear2d (20000 rounds) - upsampling to 800x800
Elapsed time (ms): 3.2692901134490966

---- END Benchmark 2D ----


---- Benchmark 1D ----

Input tensor: [4, 512, 320]
Input is_contiguous memory_format torch.channels_last: False
Input is_contiguous : True

- Bench upsample_linear1d (20000 rounds) - downsampling to 256
Elapsed time (ms): 0.2808334469795227

- Bench upsample_linear1d (20000 rounds) - upsampling to 512
Elapsed time (ms): 0.5523531079292296

---- END Benchmark 1D ----


---- Benchmark 3D ----

Input tensor: [1, 3, 16, 320, 320]
Input is_contiguous memory_format torch.channels_last: False
Input is_contiguous : True

- Bench upsample_trilinear3d (2000 rounds) - downsampling to [8, 256, 256]
Elapsed time (ms): 4.401719093322754

- Bench upsample_trilinear3d (2000 rounds) - upsampling to [32, 512, 512]
Elapsed time (ms): 84.03016865253448

Input tensor: [1, 3, 16, 320, 320]
Input is_contiguous memory_format torch.channels_last: True
Input is_contiguous : False

- Bench upsample_trilinear3d (2000 rounds) - downsampling to [8, 256, 256]
Elapsed time (ms): 13.609782457351685

- Bench upsample_trilinear3d (2000 rounds) - upsampling to [32, 512, 512]
Elapsed time (ms): 246.63803946971893

---- END Benchmark 3D ----



__version__ = 1.8.0.dev20210208+cu110
debug = False
cuda = 11.0
git_version = 71e7186e5dcb44fb9e9bacf841a11f3cfd3215f8
hip = None


Torch config: PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) Math Kernel Library Version 2020.0.0 Product Build 20191122 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v1.7.0 (Git Hash 7aed236906b1f7a05c0917e5257a1af05e9ff683)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.0
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80
  - CuDNN 8.0.5
  - Magma 2.5.2
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.0, CUDNN_VERSION=8.0.5, CXX_COMPILER=/opt/rh/devtoolset-7/root/usr/bin/c++, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.8.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, 

Num threads: 1


---- Benchmark 2D ----

Input tensor: [1, 3, 320, 320]
Input is_contiguous memory_format torch.channels_last: False
Input is_contiguous : True

- Bench upsample_bilinear2d (20000 rounds) - downsampling to 256x256
Elapsed time (ms): 0.8966643810272217

- Bench upsample_bilinear2d (20000 rounds) - upsampling to 512x512
Elapsed time (ms): 3.5398606896400455

Input tensor: [1, 3, 320, 320]
Input is_contiguous memory_format torch.channels_last: False
Input is_contiguous : False

- Bench upsample_bilinear2d (20000 rounds) - downsampling to 256x256
Elapsed time (ms): 0.9759848594665528

- Bench upsample_bilinear2d (20000 rounds) - upsampling to 512x512
Elapsed time (ms): 3.626580238342285

Input tensor: [1, 3, 320, 320]
Input is_contiguous memory_format torch.channels_last: True
Input is_contiguous : False

- Bench upsample_bilinear2d (20000 rounds) - downsampling to 256x256
Elapsed time (ms): 1.0093165397644044

- Bench upsample_bilinear2d (20000 rounds) - upsampling to 512x512
Elapsed time (ms): 4.02310037612915

1 - Test size as in https://github.com/mingfeima/op_bench-py

Input tensor: [32, 128, 64, 64]
Input is_contiguous memory_format torch.channels_last: True
Input is_contiguous : False

- Bench upsample_bilinear2d (2000 rounds) - downsampling to 32x32
Elapsed time (ms): 5.873640775680542

- Bench upsample_bilinear2d (2000 rounds) - upsampling to 128x128
Elapsed time (ms): 108.25413906574249

2 - Test size as in https://github.com/mingfeima/op_bench-py

Input tensor: [32, 128, 64, 64]
Input is_contiguous memory_format torch.channels_last: False
Input is_contiguous : True

- Bench upsample_bilinear2d (2000 rounds) - downsampling to 32x32
Elapsed time (ms): 19.912200927734375

- Bench upsample_bilinear2d (2000 rounds) - upsampling to 128x128
Elapsed time (ms): 398.8195677995682

Input tensor: [1, 3, 500, 500]
Input is_contiguous memory_format torch.channels_last: False
Input is_contiguous : True

- Bench upsample_bilinear2d (20000 rounds) - downsampling to 256x256
Elapsed time (ms): 0.8944316744804381

- Bench upsample_bilinear2d (20000 rounds) - upsampling to 800x800
Elapsed time (ms): 8.632744765281679

Input tensor: [1, 3, 500, 500]
Input is_contiguous memory_format torch.channels_last: False
Input is_contiguous : False

- Bench upsample_bilinear2d (20000 rounds) - downsampling to 256x256
Elapsed time (ms): 1.0921003222465515

- Bench upsample_bilinear2d (20000 rounds) - upsampling to 800x800
Elapsed time (ms): 8.939404881000518

---- END Benchmark 2D ----


---- Benchmark 1D ----

Input tensor: [4, 512, 320]
Input is_contiguous memory_format torch.channels_last: False
Input is_contiguous : True

- Bench upsample_linear1d (20000 rounds) - downsampling to 256
Elapsed time (ms): 1.5233286499977112

- Bench upsample_linear1d (20000 rounds) - upsampling to 512
Elapsed time (ms): 3.0312371730804446

---- END Benchmark 1D ----


---- Benchmark 3D ----

Input tensor: [1, 3, 16, 320, 320]
Input is_contiguous memory_format torch.channels_last: False
Input is_contiguous : True

- Bench upsample_trilinear3d (2000 rounds) - downsampling to [8, 256, 256]
Elapsed time (ms): 12.040798902511597

- Bench upsample_trilinear3d (2000 rounds) - upsampling to [32, 512, 512]
Elapsed time (ms): 222.83794116973877

Input tensor: [1, 3, 16, 320, 320]
Input is_contiguous memory_format torch.channels_last: True
Input is_contiguous : False

- Bench upsample_trilinear3d (2000 rounds) - downsampling to [8, 256, 256]
Elapsed time (ms): 13.303568959236145

- Bench upsample_trilinear3d (2000 rounds) - upsampling to [32, 512, 512]
Elapsed time (ms): 245.9575320482254

---- END Benchmark 3D ----
