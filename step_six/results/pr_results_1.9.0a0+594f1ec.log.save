
__version__ = 1.9.0a0+594f1ec
debug = False
cuda = 11.1
git_version = 594f1ecca2dfb384ea5954f8da8c8979df271f4a
hip = None


Torch config: PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - CPU capability usage: AVX2
  - CUDA Runtime 11.1
  - NVCC architecture flags: -gencode;arch=compute_61,code=sm_61
  - CuDNN 8.0.5
  - Build settings: BUILD_TYPE=Release, CUDA_VERSION=11.1, CUDNN_VERSION=8.0.5, CXX_COMPILER=/usr/bin/g++-7, CXX_FLAGS=-O3 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_PYTORCH_QNNPACK -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.9.0, USE_CUDA=1, USE_CUDNN=1, USE_EIGEN_FOR_BLAS=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=OFF, USE_MKLDNN=OFF, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=0, USE_OPENMP=ON, 

Num threads: 6


---- Benchmark 2D ----

Input tensor: [1, 3, 320, 320]
Input is_contiguous memory_format torch.channels_last: False
Input is_contiguous : True

- Bench upsample_bilinear2d (20000 rounds) - downsampling to 256x256
Elapsed time (ms): 0.07886412143707275

- Bench upsample_bilinear2d (20000 rounds) - upsampling to 512x512
Elapsed time (ms): 0.40931652784347533

Input tensor: [1, 3, 320, 320]
Input is_contiguous memory_format torch.channels_last: False
Input is_contiguous : False

- Bench upsample_bilinear2d (20000 rounds) - downsampling to 256x256
Elapsed time (ms): 0.07756161689758301

- Bench upsample_bilinear2d (20000 rounds) - upsampling to 512x512
Elapsed time (ms): 0.4087469816207886

Input tensor: [1, 3, 320, 320]
Input is_contiguous memory_format torch.channels_last: True
Input is_contiguous : False

- Bench upsample_bilinear2d (20000 rounds) - downsampling to 256x256
Elapsed time (ms): 1.0896942615509033

- Bench upsample_bilinear2d (20000 rounds) - upsampling to 512x512
Elapsed time (ms): 4.238735890388489

1 - Test size as in https://github.com/mingfeima/op_bench-py

Input tensor: [32, 128, 64, 64]
Input is_contiguous memory_format torch.channels_last: True
Input is_contiguous : False

- Bench upsample_bilinear2d (2000 rounds) - downsampling to 32x32
Elapsed time (ms): 2.284687876701355

- Bench upsample_bilinear2d (2000 rounds) - upsampling to 128x128
Elapsed time (ms): 35.969621896743774

2 - Test size as in https://github.com/mingfeima/op_bench-py

Input tensor: [32, 128, 64, 64]
Input is_contiguous memory_format torch.channels_last: False
Input is_contiguous : True

- Bench upsample_bilinear2d (2000 rounds) - downsampling to 32x32
Elapsed time (ms): 2.437732219696045

- Bench upsample_bilinear2d (2000 rounds) - upsampling to 128x128
Elapsed time (ms): 52.43665301799774

Input tensor: [1, 3, 500, 500]
Input is_contiguous memory_format torch.channels_last: False
Input is_contiguous : True

- Bench upsample_bilinear2d (20000 rounds) - downsampling to 256x256
Elapsed time (ms): 0.07822500467300415

- Bench upsample_bilinear2d (20000 rounds) - upsampling to 800x800
Elapsed time (ms): 0.5604660272598266

Input tensor: [1, 3, 500, 500]
Input is_contiguous memory_format torch.channels_last: False
Input is_contiguous : False

- Bench upsample_bilinear2d (20000 rounds) - downsampling to 256x256
Elapsed time (ms): 0.07927006483078003

- Bench upsample_bilinear2d (20000 rounds) - upsampling to 800x800
Elapsed time (ms): 0.5630805253982544

---- END Benchmark 2D ----


---- Benchmark 1D ----

Input tensor: [4, 512, 320]
Input is_contiguous memory_format torch.channels_last: False
Input is_contiguous : True

- Bench upsample_linear1d (20000 rounds) - downsampling to 256
Elapsed time (ms): 0.10358200073242188

- Bench upsample_linear1d (20000 rounds) - upsampling to 512
Elapsed time (ms): 0.1883918523788452

---- END Benchmark 1D ----


---- Benchmark 3D ----

Input tensor: [1, 3, 16, 320, 320]
Input is_contiguous memory_format torch.channels_last: False
Input is_contiguous : True

- Bench upsample_trilinear3d (2000 rounds) - downsampling to [8, 256, 256]
Elapsed time (ms): 2.0948145389556885

- Bench upsample_trilinear3d (2000 rounds) - upsampling to [32, 512, 512]
Elapsed time (ms): 42.649837136268616

Input tensor: [1, 3, 16, 320, 320]
Input is_contiguous memory_format torch.channels_last: True
Input is_contiguous : False

- Bench upsample_trilinear3d (2000 rounds) - downsampling to [8, 256, 256]
Elapsed time (ms): 13.657591342926025

- Bench upsample_trilinear3d (2000 rounds) - upsampling to [32, 512, 512]
Elapsed time (ms): 246.2547128200531

---- END Benchmark 3D ----



__version__ = 1.9.0a0+594f1ec
debug = False
cuda = 11.1
git_version = 594f1ecca2dfb384ea5954f8da8c8979df271f4a
hip = None


Torch config: PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - CPU capability usage: AVX2
  - CUDA Runtime 11.1
  - NVCC architecture flags: -gencode;arch=compute_61,code=sm_61
  - CuDNN 8.0.5
  - Build settings: BUILD_TYPE=Release, CUDA_VERSION=11.1, CUDNN_VERSION=8.0.5, CXX_COMPILER=/usr/bin/g++-7, CXX_FLAGS=-O3 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_PYTORCH_QNNPACK -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.9.0, USE_CUDA=1, USE_CUDNN=1, USE_EIGEN_FOR_BLAS=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=OFF, USE_MKLDNN=OFF, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=0, USE_OPENMP=ON, 

Num threads: 1


---- Benchmark 2D ----

Input tensor: [1, 3, 320, 320]
Input is_contiguous memory_format torch.channels_last: False
Input is_contiguous : True

- Bench upsample_bilinear2d (20000 rounds) - downsampling to 256x256
Elapsed time (ms): 0.329777204990387

- Bench upsample_bilinear2d (20000 rounds) - upsampling to 512x512
Elapsed time (ms): 1.7586658120155334

Input tensor: [1, 3, 320, 320]
Input is_contiguous memory_format torch.channels_last: False
Input is_contiguous : False

- Bench upsample_bilinear2d (20000 rounds) - downsampling to 256x256
Elapsed time (ms): 0.32957136631011963

- Bench upsample_bilinear2d (20000 rounds) - upsampling to 512x512
Elapsed time (ms): 1.763187003135681

Input tensor: [1, 3, 320, 320]
Input is_contiguous memory_format torch.channels_last: True
Input is_contiguous : False

- Bench upsample_bilinear2d (20000 rounds) - downsampling to 256x256
Elapsed time (ms): 1.007518208026886

- Bench upsample_bilinear2d (20000 rounds) - upsampling to 512x512
Elapsed time (ms): 4.00889230966568

1 - Test size as in https://github.com/mingfeima/op_bench-py

Input tensor: [32, 128, 64, 64]
Input is_contiguous memory_format torch.channels_last: True
Input is_contiguous : False

- Bench upsample_bilinear2d (2000 rounds) - downsampling to 32x32
Elapsed time (ms): 5.886129379272461

- Bench upsample_bilinear2d (2000 rounds) - upsampling to 128x128
Elapsed time (ms): 107.54705131053925

2 - Test size as in https://github.com/mingfeima/op_bench-py

Input tensor: [32, 128, 64, 64]
Input is_contiguous memory_format torch.channels_last: False
Input is_contiguous : True

- Bench upsample_bilinear2d (2000 rounds) - downsampling to 32x32
Elapsed time (ms): 10.050315141677856

- Bench upsample_bilinear2d (2000 rounds) - upsampling to 128x128
Elapsed time (ms): 204.6446783542633

Input tensor: [1, 3, 500, 500]
Input is_contiguous memory_format torch.channels_last: False
Input is_contiguous : True

- Bench upsample_bilinear2d (20000 rounds) - downsampling to 256x256
Elapsed time (ms): 0.33576762676239014

- Bench upsample_bilinear2d (20000 rounds) - upsampling to 800x800
Elapsed time (ms): 2.951205790042877

Input tensor: [1, 3, 500, 500]
Input is_contiguous memory_format torch.channels_last: False
Input is_contiguous : False

- Bench upsample_bilinear2d (20000 rounds) - downsampling to 256x256
Elapsed time (ms): 0.3404280304908752

- Bench upsample_bilinear2d (20000 rounds) - upsampling to 800x800
Elapsed time (ms): 2.961883521080017

---- END Benchmark 2D ----


---- Benchmark 1D ----

Input tensor: [4, 512, 320]
Input is_contiguous memory_format torch.channels_last: False
Input is_contiguous : True

- Bench upsample_linear1d (20000 rounds) - downsampling to 256
Elapsed time (ms): 0.5064866423606872

- Bench upsample_linear1d (20000 rounds) - upsampling to 512
Elapsed time (ms): 0.9800663232803345

---- END Benchmark 1D ----


---- Benchmark 3D ----

Input tensor: [1, 3, 16, 320, 320]
Input is_contiguous memory_format torch.channels_last: False
Input is_contiguous : True

- Bench upsample_trilinear3d (2000 rounds) - downsampling to [8, 256, 256]
Elapsed time (ms): 11.303557634353638

- Bench upsample_trilinear3d (2000 rounds) - upsampling to [32, 512, 512]
Elapsed time (ms): 209.67745316028595

Input tensor: [1, 3, 16, 320, 320]
Input is_contiguous memory_format torch.channels_last: True
Input is_contiguous : False

- Bench upsample_trilinear3d (2000 rounds) - downsampling to [8, 256, 256]
Elapsed time (ms): 13.322856307029724

- Bench upsample_trilinear3d (2000 rounds) - upsampling to [32, 512, 512]
Elapsed time (ms): 245.58394241333008

---- END Benchmark 3D ----
