
No CUDA runtime is found, using CUDA_HOME='/usr/local/cuda'
__version__ = 1.9.0a0+git6aa5148
debug = False
cuda = None
git_version = 6aa5148df21d5583cf2ae3f95c992d207ed2e281
hip = None


Uses custom tests config:  ['2dcf', '2dcl', '3dcf', '3dcl', '1d']
Torch config: PyTorch built with:
  - GCC 9.3
  - C++ Version: 201402
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - CPU capability usage: AVX2
  - Build settings: BUILD_TYPE=Release, CXX_COMPILER=/usr/lib/ccache/c++, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_PYTORCH_QNNPACK -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.9.0, USE_CUDA=0, USE_CUDNN=OFF, USE_EIGEN_FOR_BLAS=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=OFF, USE_MKLDNN=OFF, USE_MPI=OFF, USE_NCCL=OFF, USE_NNPACK=0, USE_OPENMP=ON, 

Num threads: 6


---- Benchmark 2D ----

Input tensor: [1, 3, 320, 320]
Input is_contiguous memory_format torch.channels_last: False
Input is_contiguous : True

- Bench upsample_bilinear2d (15 min_run_time) - downsampling to 256x256
<torch.utils.benchmark.utils.common.Measurement object at 0x7fbefb7696d0>
upsample_bilinear2d channels_first contiguous: [1, 3, 320, 320] -> (256, 256)
1.9.0a0+git6aa5148
  Median: 73.32 us
  IQR:    0.18 us (73.24 to 73.42)
  205 measurements, 1000 runs per measurement, 6 threads

- Bench upsample_bilinear2d (15 min_run_time) - upsampling to 512x512
<torch.utils.benchmark.utils.common.Measurement object at 0x7fbefb7697c0>
upsample_bilinear2d channels_first contiguous: [1, 3, 320, 320] -> (512, 512)
1.9.0a0+git6aa5148
  Median: 232.02 us
  IQR:    0.80 us (231.80 to 232.60)
  644 measurements, 100 runs per measurement, 6 threads

Input tensor: [1, 3, 320, 320]
Input is_contiguous memory_format torch.channels_last: False
Input is_contiguous : False

- Bench upsample_bilinear2d (15 min_run_time) - downsampling to 256x256
<torch.utils.benchmark.utils.common.Measurement object at 0x7fbefb769820>
upsample_bilinear2d channels_first non-contiguous: [1, 3, 320, 320] -> (256, 256)
1.9.0a0+git6aa5148
  Median: 74.05 us
  IQR:    0.10 us (74.00 to 74.10)
  202 measurements, 1000 runs per measurement, 6 threads

- Bench upsample_bilinear2d (15 min_run_time) - upsampling to 512x512
<torch.utils.benchmark.utils.common.Measurement object at 0x7fbefb769670>
upsample_bilinear2d channels_first non-contiguous: [1, 3, 320, 320] -> (512, 512)
1.9.0a0+git6aa5148
  Median: 232.62 us
  IQR:    0.55 us (232.28 to 232.84)
  643 measurements, 100 runs per measurement, 6 threads

Input tensor: [1, 3, 320, 320]
Input is_contiguous memory_format torch.channels_last: True
Input is_contiguous : False

- Bench upsample_bilinear2d (15 min_run_time) - downsampling to 256x256
<torch.utils.benchmark.utils.common.Measurement object at 0x7fbefb7698b0>
upsample_bilinear2d channels_last non-contiguous: [1, 3, 320, 320] -> (256, 256)
1.9.0a0+git6aa5148
  Median: 1.09 ms
  IQR:    0.00 ms (1.09 to 1.09)
  138 measurements, 100 runs per measurement, 6 threads

- Bench upsample_bilinear2d (15 min_run_time) - upsampling to 512x512
<torch.utils.benchmark.utils.common.Measurement object at 0x7fbefb769b20>
upsample_bilinear2d channels_last non-contiguous: [1, 3, 320, 320] -> (512, 512)
1.9.0a0+git6aa5148
  Median: 4.23 ms
  IQR:    0.01 ms (4.23 to 4.24)
  354 measurements, 10 runs per measurement, 6 threads

1 - Test size as in https://github.com/mingfeima/op_bench-py

Input tensor: [32, 128, 64, 64]
Input is_contiguous memory_format torch.channels_last: True
Input is_contiguous : False

- Bench upsample_bilinear2d (15 min_run_time) - downsampling to 32x32
<torch.utils.benchmark.utils.common.Measurement object at 0x7fbefb769460>
upsample_bilinear2d channels_last non-contiguous: [32, 128, 64, 64] -> (32, 32)
1.9.0a0+git6aa5148
  Median: 2.27 ms
  IQR:    0.00 ms (2.27 to 2.27)
  661 measurements, 10 runs per measurement, 6 threads

- Bench upsample_bilinear2d (15 min_run_time) - upsampling to 128x128
<torch.utils.benchmark.utils.common.Measurement object at 0x7fbefb769520>
upsample_bilinear2d channels_last non-contiguous: [32, 128, 64, 64] -> (128, 128)
1.9.0a0+git6aa5148
  Median: 36.64 ms
  IQR:    0.79 ms (36.16 to 36.96)
  410 measurements, 1 runs per measurement, 6 threads

1.2 - Test sizes similar to https://github.com/pytorch/pytorch/blob/master/benchmarks/operator_benchmark/pt/interpolate_test.py

Input tensor: [2, 128, 64, 46]
Input is_contiguous memory_format torch.channels_last: True
Input is_contiguous : False

- Bench upsample_bilinear2d (15 min_run_time) - downsampling to 32x32
<torch.utils.benchmark.utils.common.Measurement object at 0x7fbefb7695b0>
upsample_bilinear2d channels_last non-contiguous: [2, 128, 64, 46] -> (32, 32)
1.9.0a0+git6aa5148
  Median: 60.61 us
  IQR:    0.08 us (60.57 to 60.65)
  248 measurements, 1000 runs per measurement, 6 threads

- Bench upsample_bilinear2d (15 min_run_time) - upsampling to 128x128
<torch.utils.benchmark.utils.common.Measurement object at 0x7fbefb769340>
upsample_bilinear2d channels_last non-contiguous: [2, 128, 64, 46] -> (128, 128)
1.9.0a0+git6aa5148
  Median: 912.43 us
  IQR:    0.88 us (912.03 to 912.90)
  165 measurements, 100 runs per measurement, 6 threads

2 - Test size as in https://github.com/mingfeima/op_bench-py

Input tensor: [32, 128, 64, 64]
Input is_contiguous memory_format torch.channels_last: False
Input is_contiguous : True

- Bench upsample_bilinear2d (15 min_run_time) - downsampling to 32x32
<torch.utils.benchmark.utils.common.Measurement object at 0x7fbefb769430>
upsample_bilinear2d channels_first contiguous: [32, 128, 64, 64] -> (32, 32)
1.9.0a0+git6aa5148
  Median: 2.31 ms
  IQR:    0.00 ms (2.31 to 2.31)
  649 measurements, 10 runs per measurement, 6 threads

- Bench upsample_bilinear2d (15 min_run_time) - upsampling to 128x128
<torch.utils.benchmark.utils.common.Measurement object at 0x7fbefb769130>
upsample_bilinear2d channels_first contiguous: [32, 128, 64, 64] -> (128, 128)
1.9.0a0+git6aa5148
  Median: 51.81 ms
  IQR:    0.50 ms (51.63 to 52.13)
  289 measurements, 1 runs per measurement, 6 threads

Input tensor: [1, 3, 500, 500]
Input is_contiguous memory_format torch.channels_last: False
Input is_contiguous : True

- Bench upsample_bilinear2d (15 min_run_time) - downsampling to 256x256
<torch.utils.benchmark.utils.common.Measurement object at 0x7fbefb769a00>
upsample_bilinear2d channels_first contiguous: [1, 3, 500, 500] -> (256, 256)
1.9.0a0+git6aa5148
  Median: 75.65 us
  IQR:    0.08 us (75.60 to 75.69)
  198 measurements, 1000 runs per measurement, 6 threads

- Bench upsample_bilinear2d (15 min_run_time) - upsampling to 800x800
<torch.utils.benchmark.utils.common.Measurement object at 0x7fbefb769370>
upsample_bilinear2d channels_first contiguous: [1, 3, 500, 500] -> (800, 800)
1.9.0a0+git6aa5148
  Median: 535.47 us
  IQR:    0.50 us (535.24 to 535.74)
  280 measurements, 100 runs per measurement, 6 threads

Input tensor: [1, 3, 500, 500]
Input is_contiguous memory_format torch.channels_last: False
Input is_contiguous : False

- Bench upsample_bilinear2d (15 min_run_time) - downsampling to 256x256
<torch.utils.benchmark.utils.common.Measurement object at 0x7fbefb795eb0>
upsample_bilinear2d channels_first non-contiguous: [1, 3, 500, 500] -> (256, 256)
1.9.0a0+git6aa5148
  Median: 75.94 us
  IQR:    0.09 us (75.89 to 75.98)
  197 measurements, 1000 runs per measurement, 6 threads

- Bench upsample_bilinear2d (15 min_run_time) - upsampling to 800x800
<torch.utils.benchmark.utils.common.Measurement object at 0x7fbefb795e20>
upsample_bilinear2d channels_first non-contiguous: [1, 3, 500, 500] -> (800, 800)
1.9.0a0+git6aa5148
  Median: 537.91 us
  IQR:    0.36 us (537.78 to 538.13)
  279 measurements, 100 runs per measurement, 6 threads

Input tensor: [1, 3, 500, 500]
Input is_contiguous memory_format torch.channels_last: True
Input is_contiguous : False

- Bench upsample_bilinear2d (15 min_run_time) - downsampling to 256x256
<torch.utils.benchmark.utils.common.Measurement object at 0x7fbf148d3490>
upsample_bilinear2d channels_last non-contiguous: [1, 3, 500, 500] -> (256, 256)
1.9.0a0+git6aa5148
  Median: 1.09 ms
  IQR:    0.00 ms (1.09 to 1.09)
  137 measurements, 100 runs per measurement, 6 threads

- Bench upsample_bilinear2d (15 min_run_time) - upsampling to 800x800
<torch.utils.benchmark.utils.common.Measurement object at 0x7fbefb795f40>
upsample_bilinear2d channels_last non-contiguous: [1, 3, 500, 500] -> (800, 800)
1.9.0a0+git6aa5148
  Median: 10.10 ms
  IQR:    0.01 ms (10.10 to 10.11)
  149 measurements, 10 runs per measurement, 6 threads

---- END Benchmark 2D ----


---- Benchmark 1D ----

Input tensor: [4, 512, 320]
Input is_contiguous memory_format torch.channels_last: False
Input is_contiguous : True

- Bench upsample_linear1d (15 min_run_time) - downsampling to 256
<torch.utils.benchmark.utils.common.Measurement object at 0x7fbefb769a30>
upsample_linear1d channels_first contiguous: [4, 512, 320] -> [256]
1.9.0a0+git6aa5148
  Median: 104.23 us
  IQR:    0.23 us (104.09 to 104.31)
  1430 measurements, 100 runs per measurement, 6 threads

- Bench upsample_linear1d (15 min_run_time) - upsampling to 512
<torch.utils.benchmark.utils.common.Measurement object at 0x7fbefb7697f0>
upsample_linear1d channels_first contiguous: [4, 512, 320] -> [512]
1.9.0a0+git6aa5148
  Median: 192.60 us
  IQR:    0.19 us (192.51 to 192.70)
  778 measurements, 100 runs per measurement, 6 threads

---- END Benchmark 1D ----


---- Benchmark 3D ----

Input tensor: [1, 3, 16, 320, 320]
Input is_contiguous memory_format torch.channels_last: False
Input is_contiguous : True

- Bench upsample_trilinear3d (15 min_run_time) - downsampling to [8, 256, 256]
<torch.utils.benchmark.utils.common.Measurement object at 0x7fbefb769d60>
upsample_trilinear3d channels_first contiguous: [1, 3, 16, 320, 320] -> [8, 256, 256]
1.9.0a0+git6aa5148
  Median: 2.10 ms
  IQR:    0.00 ms (2.10 to 2.10)
  713 measurements, 10 runs per measurement, 6 threads

- Bench upsample_trilinear3d (15 min_run_time) - upsampling to [32, 512, 512]
<torch.utils.benchmark.utils.common.Measurement object at 0x7fbefb769280>
upsample_trilinear3d channels_first contiguous: [1, 3, 16, 320, 320] -> [32, 512, 512]
1.9.0a0+git6aa5148
  Median: 42.82 ms
  IQR:    0.34 ms (42.70 to 43.04)
  349 measurements, 1 runs per measurement, 6 threads

Input tensor: [1, 3, 16, 320, 320]
Input is_contiguous memory_format torch.channels_last: True
Input is_contiguous : False

- Bench upsample_trilinear3d (15 min_run_time) - downsampling to [8, 256, 256]
<torch.utils.benchmark.utils.common.Measurement object at 0x7fbefb769a90>
upsample_trilinear3d channels_last non-contiguous: [1, 3, 16, 320, 320] -> [8, 256, 256]
1.9.0a0+git6aa5148
  Median: 14.12 ms
  IQR:    0.04 ms (14.10 to 14.14)
  1062 measurements, 1 runs per measurement, 6 threads

- Bench upsample_trilinear3d (15 min_run_time) - upsampling to [32, 512, 512]
<torch.utils.benchmark.utils.common.Measurement object at 0x7fbefb769400>
upsample_trilinear3d channels_last non-contiguous: [1, 3, 16, 320, 320] -> [32, 512, 512]
1.9.0a0+git6aa5148
  Median: 254.75 ms
  IQR:    0.22 ms (254.66 to 254.88)
  59 measurements, 1 runs per measurement, 6 threads

---- END Benchmark 3D ----



No CUDA runtime is found, using CUDA_HOME='/usr/local/cuda'
__version__ = 1.9.0a0+git6aa5148
debug = False
cuda = None
git_version = 6aa5148df21d5583cf2ae3f95c992d207ed2e281
hip = None


Uses custom tests config:  ['2dcf', '2dcl', '3dcf', '3dcl', '1d']
Torch config: PyTorch built with:
  - GCC 9.3
  - C++ Version: 201402
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - CPU capability usage: AVX2
  - Build settings: BUILD_TYPE=Release, CXX_COMPILER=/usr/lib/ccache/c++, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_PYTORCH_QNNPACK -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.9.0, USE_CUDA=0, USE_CUDNN=OFF, USE_EIGEN_FOR_BLAS=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=OFF, USE_MKLDNN=OFF, USE_MPI=OFF, USE_NCCL=OFF, USE_NNPACK=0, USE_OPENMP=ON, 

Num threads: 1


---- Benchmark 2D ----

Input tensor: [1, 3, 320, 320]
Input is_contiguous memory_format torch.channels_last: False
Input is_contiguous : True

- Bench upsample_bilinear2d (15 min_run_time) - downsampling to 256x256
<torch.utils.benchmark.utils.common.Measurement object at 0x7f790a0082e0>
upsample_bilinear2d channels_first contiguous: [1, 3, 320, 320] -> (256, 256)
1.9.0a0+git6aa5148
  Median: 315.02 us
  IQR:    0.61 us (314.59 to 315.21)
  477 measurements, 100 runs per measurement, 1 thread

- Bench upsample_bilinear2d (15 min_run_time) - upsampling to 512x512
<torch.utils.benchmark.utils.common.Measurement object at 0x7f790a0083d0>
upsample_bilinear2d channels_first contiguous: [1, 3, 320, 320] -> (512, 512)
1.9.0a0+git6aa5148
  Median: 1.18 ms
  IQR:    0.00 ms (1.18 to 1.18)
  127 measurements, 100 runs per measurement, 1 thread

Input tensor: [1, 3, 320, 320]
Input is_contiguous memory_format torch.channels_last: False
Input is_contiguous : False

- Bench upsample_bilinear2d (15 min_run_time) - downsampling to 256x256
<torch.utils.benchmark.utils.common.Measurement object at 0x7f790a008430>
upsample_bilinear2d channels_first non-contiguous: [1, 3, 320, 320] -> (256, 256)
1.9.0a0+git6aa5148
  Median: 318.10 us
  IQR:    0.62 us (317.95 to 318.57)
  472 measurements, 100 runs per measurement, 1 thread

- Bench upsample_bilinear2d (15 min_run_time) - upsampling to 512x512
<torch.utils.benchmark.utils.common.Measurement object at 0x7f790a008280>
upsample_bilinear2d channels_first non-contiguous: [1, 3, 320, 320] -> (512, 512)
1.9.0a0+git6aa5148
  Median: 1.18 ms
  IQR:    0.00 ms (1.18 to 1.19)
  127 measurements, 100 runs per measurement, 1 thread

Input tensor: [1, 3, 320, 320]
Input is_contiguous memory_format torch.channels_last: True
Input is_contiguous : False

- Bench upsample_bilinear2d (15 min_run_time) - downsampling to 256x256
<torch.utils.benchmark.utils.common.Measurement object at 0x7f790a0084c0>
upsample_bilinear2d channels_last non-contiguous: [1, 3, 320, 320] -> (256, 256)
1.9.0a0+git6aa5148
  Median: 1.01 ms
  IQR:    0.00 ms (1.01 to 1.01)
  149 measurements, 100 runs per measurement, 1 thread

- Bench upsample_bilinear2d (15 min_run_time) - upsampling to 512x512
<torch.utils.benchmark.utils.common.Measurement object at 0x7f790a008730>
upsample_bilinear2d channels_last non-contiguous: [1, 3, 320, 320] -> (512, 512)
1.9.0a0+git6aa5148
  Median: 4.00 ms
  IQR:    0.01 ms (4.00 to 4.01)
  375 measurements, 10 runs per measurement, 1 thread

1 - Test size as in https://github.com/mingfeima/op_bench-py

Input tensor: [32, 128, 64, 64]
Input is_contiguous memory_format torch.channels_last: True
Input is_contiguous : False

- Bench upsample_bilinear2d (15 min_run_time) - downsampling to 32x32
<torch.utils.benchmark.utils.common.Measurement object at 0x7f790a0087f0>
upsample_bilinear2d channels_last non-contiguous: [32, 128, 64, 64] -> (32, 32)
1.9.0a0+git6aa5148
  Median: 5.87 ms
  IQR:    0.01 ms (5.87 to 5.88)
  256 measurements, 10 runs per measurement, 1 thread

- Bench upsample_bilinear2d (15 min_run_time) - upsampling to 128x128
<torch.utils.benchmark.utils.common.Measurement object at 0x7f790a0088b0>
upsample_bilinear2d channels_last non-contiguous: [32, 128, 64, 64] -> (128, 128)
1.9.0a0+git6aa5148
  Median: 110.03 ms
  IQR:    0.27 ms (109.90 to 110.17)
  137 measurements, 1 runs per measurement, 1 thread

1.2 - Test sizes similar to https://github.com/pytorch/pytorch/blob/master/benchmarks/operator_benchmark/pt/interpolate_test.py

Input tensor: [2, 128, 64, 46]
Input is_contiguous memory_format torch.channels_last: True
Input is_contiguous : False

- Bench upsample_bilinear2d (15 min_run_time) - downsampling to 32x32
<torch.utils.benchmark.utils.common.Measurement object at 0x7f790a008940>
upsample_bilinear2d channels_last non-contiguous: [2, 128, 64, 46] -> (32, 32)
1.9.0a0+git6aa5148
  Median: 109.46 us
  IQR:    0.20 us (109.34 to 109.54)
  138 measurements, 1000 runs per measurement, 1 thread

- Bench upsample_bilinear2d (15 min_run_time) - upsampling to 128x128
<torch.utils.benchmark.utils.common.Measurement object at 0x7f790a008a30>
upsample_bilinear2d channels_last non-contiguous: [2, 128, 64, 46] -> (128, 128)
1.9.0a0+git6aa5148
  Median: 1.62 ms
  IQR:    0.01 ms (1.62 to 1.63)
  923 measurements, 10 runs per measurement, 1 thread

2 - Test size as in https://github.com/mingfeima/op_bench-py

Input tensor: [32, 128, 64, 64]
Input is_contiguous memory_format torch.channels_last: False
Input is_contiguous : True

- Bench upsample_bilinear2d (15 min_run_time) - downsampling to 32x32
<torch.utils.benchmark.utils.common.Measurement object at 0x7f790a0087c0>
upsample_bilinear2d channels_first contiguous: [32, 128, 64, 64] -> (32, 32)
1.9.0a0+git6aa5148
  Median: 9.80 ms
  IQR:    0.01 ms (9.80 to 9.81)
  154 measurements, 10 runs per measurement, 1 thread

- Bench upsample_bilinear2d (15 min_run_time) - upsampling to 128x128
<torch.utils.benchmark.utils.common.Measurement object at 0x7f790a008b20>
upsample_bilinear2d channels_first contiguous: [32, 128, 64, 64] -> (128, 128)
1.9.0a0+git6aa5148
  Median: 202.58 ms
  IQR:    0.39 ms (202.48 to 202.87)
  75 measurements, 1 runs per measurement, 1 thread

Input tensor: [1, 3, 500, 500]
Input is_contiguous memory_format torch.channels_last: False
Input is_contiguous : True

- Bench upsample_bilinear2d (15 min_run_time) - downsampling to 256x256
<torch.utils.benchmark.utils.common.Measurement object at 0x7f790a008610>
upsample_bilinear2d channels_first contiguous: [1, 3, 500, 500] -> (256, 256)
1.9.0a0+git6aa5148
  Median: 325.84 us
  IQR:    0.71 us (325.59 to 326.29)
  461 measurements, 100 runs per measurement, 1 thread

- Bench upsample_bilinear2d (15 min_run_time) - upsampling to 800x800
<torch.utils.benchmark.utils.common.Measurement object at 0x7f790a008cd0>
upsample_bilinear2d channels_first contiguous: [1, 3, 500, 500] -> (800, 800)
1.9.0a0+git6aa5148
  Median: 2.85 ms
  IQR:    0.01 ms (2.84 to 2.85)
  527 measurements, 10 runs per measurement, 1 thread

Input tensor: [1, 3, 500, 500]
Input is_contiguous memory_format torch.channels_last: False
Input is_contiguous : False

- Bench upsample_bilinear2d (15 min_run_time) - downsampling to 256x256
<torch.utils.benchmark.utils.common.Measurement object at 0x7f790a01cfd0>
upsample_bilinear2d channels_first non-contiguous: [1, 3, 500, 500] -> (256, 256)
1.9.0a0+git6aa5148
  Median: 329.36 us
  IQR:    0.58 us (329.04 to 329.63)
  456 measurements, 100 runs per measurement, 1 thread

- Bench upsample_bilinear2d (15 min_run_time) - upsampling to 800x800
<torch.utils.benchmark.utils.common.Measurement object at 0x7f790a01cd30>
upsample_bilinear2d channels_first non-contiguous: [1, 3, 500, 500] -> (800, 800)
1.9.0a0+git6aa5148
  Median: 2.85 ms
  IQR:    0.01 ms (2.85 to 2.86)
  525 measurements, 10 runs per measurement, 1 thread

Input tensor: [1, 3, 500, 500]
Input is_contiguous memory_format torch.channels_last: True
Input is_contiguous : False

- Bench upsample_bilinear2d (15 min_run_time) - downsampling to 256x256
<torch.utils.benchmark.utils.common.Measurement object at 0x7f790a01cb20>
upsample_bilinear2d channels_last non-contiguous: [1, 3, 500, 500] -> (256, 256)
1.9.0a0+git6aa5148
  Median: 1.01 ms
  IQR:    0.00 ms (1.01 to 1.01)
  149 measurements, 100 runs per measurement, 1 thread

- Bench upsample_bilinear2d (15 min_run_time) - upsampling to 800x800
<torch.utils.benchmark.utils.common.Measurement object at 0x7f790a01ca90>
upsample_bilinear2d channels_last non-contiguous: [1, 3, 500, 500] -> (800, 800)
1.9.0a0+git6aa5148
  Median: 9.79 ms
  IQR:    0.01 ms (9.78 to 9.80)
  154 measurements, 10 runs per measurement, 1 thread

---- END Benchmark 2D ----


---- Benchmark 1D ----

Input tensor: [4, 512, 320]
Input is_contiguous memory_format torch.channels_last: False
Input is_contiguous : True

- Bench upsample_linear1d (15 min_run_time) - downsampling to 256
<torch.utils.benchmark.utils.common.Measurement object at 0x7f7916966460>
upsample_linear1d channels_first contiguous: [4, 512, 320] -> [256]
1.9.0a0+git6aa5148
  Median: 516.22 us
  IQR:    0.94 us (515.84 to 516.78)
  291 measurements, 100 runs per measurement, 1 thread

- Bench upsample_linear1d (15 min_run_time) - upsampling to 512
<torch.utils.benchmark.utils.common.Measurement object at 0x7f790a0082b0>
upsample_linear1d channels_first contiguous: [4, 512, 320] -> [512]
1.9.0a0+git6aa5148
  Median: 999.20 us
  IQR:    1.61 us (998.57 to 1000.18)
  151 measurements, 100 runs per measurement, 1 thread

---- END Benchmark 1D ----


---- Benchmark 3D ----

Input tensor: [1, 3, 16, 320, 320]
Input is_contiguous memory_format torch.channels_last: False
Input is_contiguous : True

- Bench upsample_trilinear3d (15 min_run_time) - downsampling to [8, 256, 256]
<torch.utils.benchmark.utils.common.Measurement object at 0x7f790a008100>
upsample_trilinear3d channels_first contiguous: [1, 3, 16, 320, 320] -> [8, 256, 256]
1.9.0a0+git6aa5148
  Median: 11.39 ms
  IQR:    0.02 ms (11.38 to 11.40)
  132 measurements, 10 runs per measurement, 1 thread

- Bench upsample_trilinear3d (15 min_run_time) - upsampling to [32, 512, 512]
<torch.utils.benchmark.utils.common.Measurement object at 0x7f790a008ca0>
upsample_trilinear3d channels_first contiguous: [1, 3, 16, 320, 320] -> [32, 512, 512]
1.9.0a0+git6aa5148
  Median: 210.53 ms
  IQR:    0.24 ms (210.42 to 210.65)
  72 measurements, 1 runs per measurement, 1 thread

Input tensor: [1, 3, 16, 320, 320]
Input is_contiguous memory_format torch.channels_last: True
Input is_contiguous : False

- Bench upsample_trilinear3d (15 min_run_time) - downsampling to [8, 256, 256]
<torch.utils.benchmark.utils.common.Measurement object at 0x7f790a0086a0>
upsample_trilinear3d channels_last non-contiguous: [1, 3, 16, 320, 320] -> [8, 256, 256]
1.9.0a0+git6aa5148
  Median: 13.82 ms
  IQR:    0.01 ms (13.82 to 13.83)
  109 measurements, 10 runs per measurement, 1 thread

- Bench upsample_trilinear3d (15 min_run_time) - upsampling to [32, 512, 512]
<torch.utils.benchmark.utils.common.Measurement object at 0x7f790a008790>
upsample_trilinear3d channels_last non-contiguous: [1, 3, 16, 320, 320] -> [32, 512, 512]
1.9.0a0+git6aa5148
  Median: 253.98 ms
  IQR:    0.18 ms (253.93 to 254.11)
  60 measurements, 1 runs per measurement, 1 thread

---- END Benchmark 3D ----
