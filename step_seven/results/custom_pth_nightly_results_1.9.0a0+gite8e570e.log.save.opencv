
No CUDA runtime is found, using CUDA_HOME='/usr/local/cuda'
__version__ = 1.9.0a0+gite8e570e
debug = False
cuda = None
git_version = e8e570e9c5b780bc5c1571d5f03a9914e9ca6c49
hip = None


Uses tests cases:  ['linear:2dcl']
Torch config: PyTorch built with:
  - GCC 9.3
  - C++ Version: 201402
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - CPU capability usage: AVX2
  - Build settings: BUILD_TYPE=Release, CXX_COMPILER=/usr/lib/ccache/c++, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_PYTORCH_QNNPACK -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.9.0, USE_CUDA=0, USE_CUDNN=OFF, USE_EIGEN_FOR_BLAS=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=OFF, USE_MKLDNN=OFF, USE_MPI=OFF, USE_NCCL=OFF, USE_NNPACK=0, USE_OPENMP=ON, 

Num threads: 6


---- Benchmark linear 2D ----

Input tensor: [1, 3, 320, 320]
Input is_contiguous memory_format torch.channels_last: True
Input is_contiguous : False

- Bench upsample linear 2d (1 min_run_time) - downsampling to 256x256
<torch.utils.benchmark.utils.common.Measurement object at 0x7f523d5941c0>
upsample_bilinear2d channels_last non-contiguous: [1, 3, 320, 320] -> (256, 256)
1.9.0a0+gite8e570e
  Median: 1.09 ms
  IQR:    0.00 ms (1.09 to 1.10)
  887 measurements, 1 runs per measurement, 6 threads

- Bench upsample linear 2d (1 min_run_time) - upsampling to 512x512
<torch.utils.benchmark.utils.common.Measurement object at 0x7f523d5942b0>
upsample_bilinear2d channels_last non-contiguous: [1, 3, 320, 320] -> (512, 512)
1.9.0a0+gite8e570e
  Median: 4.25 ms
  IQR:    0.03 ms (4.24 to 4.27)
  235 measurements, 1 runs per measurement, 6 threads

1 - Test size as in https://github.com/mingfeima/op_bench-py

Input tensor: [32, 128, 64, 64]
Input is_contiguous memory_format torch.channels_last: True
Input is_contiguous : False

- Bench upsample linear 2d (1 min_run_time) - downsampling to 32x32
<torch.utils.benchmark.utils.common.Measurement object at 0x7f523d594160>
upsample_bilinear2d channels_last non-contiguous: [32, 128, 64, 64] -> (32, 32)
1.9.0a0+gite8e570e
  Median: 2.28 ms
  IQR:    0.02 ms (2.28 to 2.29)
  433 measurements, 1 runs per measurement, 6 threads

- Bench upsample linear 2d (1 min_run_time) - upsampling to 128x128
<torch.utils.benchmark.utils.common.Measurement object at 0x7f523d594370>
upsample_bilinear2d channels_last non-contiguous: [32, 128, 64, 64] -> (128, 128)
1.9.0a0+gite8e570e
  Median: 36.44 ms
  IQR:    1.24 ms (35.62 to 36.86)
  28 measurements, 1 runs per measurement, 6 threads

1.2 - Test sizes similar to https://github.com/pytorch/pytorch/blob/master/benchmarks/operator_benchmark/pt/interpolate_test.py

Input tensor: [2, 128, 64, 46]
Input is_contiguous memory_format torch.channels_last: True
Input is_contiguous : False

- Bench upsample linear 2d (1 min_run_time) - downsampling to 32x32
<torch.utils.benchmark.utils.common.Measurement object at 0x7f523d594610>
upsample_bilinear2d channels_last non-contiguous: [2, 128, 64, 46] -> (32, 32)
1.9.0a0+gite8e570e
  Median: 67.19 us
  IQR:    4.95 us (62.39 to 67.34)
  153 measurements, 100 runs per measurement, 6 threads

- Bench upsample linear 2d (1 min_run_time) - upsampling to 128x128
<torch.utils.benchmark.utils.common.Measurement object at 0x7f523d5945e0>
upsample_bilinear2d channels_last non-contiguous: [2, 128, 64, 46] -> (128, 128)
1.9.0a0+gite8e570e
  Median: 903.78 us
  IQR:    10.69 us (900.68 to 911.37)
  1098 measurements, 1 runs per measurement, 6 threads

1.3 - Test sizes similar to https://github.com/pytorch/pytorch/blob/master/benchmarks/operator_benchmark/pt/interpolate_test.py

Input tensor: [1, 128, 64, 46]
Input is_contiguous memory_format torch.channels_last: True
Input is_contiguous : False

- Bench upsample linear 2d (1 min_run_time) - downsampling to 32x32
<torch.utils.benchmark.utils.common.Measurement object at 0x7f523d5946a0>
upsample_bilinear2d channels_last non-contiguous: [1, 128, 64, 46] -> (32, 32)
1.9.0a0+gite8e570e
  Median: 60.73 us
  IQR:    0.08 us (60.70 to 60.78)
  165 measurements, 100 runs per measurement, 6 threads

- Bench upsample linear 2d (1 min_run_time) - upsampling to 128x128
<torch.utils.benchmark.utils.common.Measurement object at 0x7f523d594790>
upsample_bilinear2d channels_last non-contiguous: [1, 128, 64, 46] -> (128, 128)
1.9.0a0+gite8e570e
  Median: 581.84 us
  IQR:    0.79 us (581.49 to 582.28)
  171 measurements, 10 runs per measurement, 6 threads

Input tensor: [1, 3, 500, 500]
Input is_contiguous memory_format torch.channels_last: True
Input is_contiguous : False

- Bench upsample linear 2d (1 min_run_time) - downsampling to 256x256
<torch.utils.benchmark.utils.common.Measurement object at 0x7f523d594820>
upsample_bilinear2d channels_last non-contiguous: [1, 3, 500, 500] -> (256, 256)
1.9.0a0+gite8e570e
  Median: 1.09 ms
  IQR:    0.00 ms (1.09 to 1.10)
  911 measurements, 1 runs per measurement, 6 threads

- Bench upsample linear 2d (1 min_run_time) - upsampling to 800x800
<torch.utils.benchmark.utils.common.Measurement object at 0x7f523d594910>
upsample_bilinear2d channels_last non-contiguous: [1, 3, 500, 500] -> (800, 800)
1.9.0a0+gite8e570e
  Median: 10.16 ms
  IQR:    0.06 ms (10.13 to 10.19)
  99 measurements, 1 runs per measurement, 6 threads

---- END Benchmark linear 2D ----


---- Benchmark linear 1D ----

---- END Benchmark linear 1D ----


---- Benchmark linear 3D ----

---- END Benchmark linear 3D ----


---- Benchmark nearest 2D ----

---- END Benchmark nearest 2D ----


---- Benchmark nearest 1D ----

---- END Benchmark nearest 1D ----


---- Benchmark nearest 3D ----

---- END Benchmark nearest 3D ----


---- Benchmark cubic 2D ----

---- END Benchmark cubic 2D ----



No CUDA runtime is found, using CUDA_HOME='/usr/local/cuda'
__version__ = 1.9.0a0+gite8e570e
debug = False
cuda = None
git_version = e8e570e9c5b780bc5c1571d5f03a9914e9ca6c49
hip = None


Uses tests cases:  ['linear:2dcl']
Torch config: PyTorch built with:
  - GCC 9.3
  - C++ Version: 201402
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - CPU capability usage: AVX2
  - Build settings: BUILD_TYPE=Release, CXX_COMPILER=/usr/lib/ccache/c++, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_PYTORCH_QNNPACK -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.9.0, USE_CUDA=0, USE_CUDNN=OFF, USE_EIGEN_FOR_BLAS=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=OFF, USE_MKLDNN=OFF, USE_MPI=OFF, USE_NCCL=OFF, USE_NNPACK=0, USE_OPENMP=ON, 

Num threads: 1


---- Benchmark linear 2D ----

Input tensor: [1, 3, 320, 320]
Input is_contiguous memory_format torch.channels_last: True
Input is_contiguous : False

- Bench upsample linear 2d (1 min_run_time) - downsampling to 256x256
<torch.utils.benchmark.utils.common.Measurement object at 0x7fb5e84a77f0>
upsample_bilinear2d channels_last non-contiguous: [1, 3, 320, 320] -> (256, 256)
1.9.0a0+gite8e570e
  Median: 1.01 ms
  IQR:    0.00 ms (1.01 to 1.01)
  983 measurements, 1 runs per measurement, 1 thread

- Bench upsample linear 2d (1 min_run_time) - upsampling to 512x512
<torch.utils.benchmark.utils.common.Measurement object at 0x7fb5e84a78e0>
upsample_bilinear2d channels_last non-contiguous: [1, 3, 320, 320] -> (512, 512)
1.9.0a0+gite8e570e
  Median: 4.07 ms
  IQR:    0.06 ms (4.02 to 4.08)
  246 measurements, 1 runs per measurement, 1 thread

1 - Test size as in https://github.com/mingfeima/op_bench-py

Input tensor: [32, 128, 64, 64]
Input is_contiguous memory_format torch.channels_last: True
Input is_contiguous : False

- Bench upsample linear 2d (1 min_run_time) - downsampling to 32x32
<torch.utils.benchmark.utils.common.Measurement object at 0x7fb5e84a7790>
upsample_bilinear2d channels_last non-contiguous: [32, 128, 64, 64] -> (32, 32)
1.9.0a0+gite8e570e
  Median: 5.91 ms
  IQR:    0.06 ms (5.87 to 5.93)
  169 measurements, 1 runs per measurement, 1 thread

- Bench upsample linear 2d (1 min_run_time) - upsampling to 128x128
<torch.utils.benchmark.utils.common.Measurement object at 0x7fb5e84a79a0>
upsample_bilinear2d channels_last non-contiguous: [32, 128, 64, 64] -> (128, 128)
1.9.0a0+gite8e570e
  Median: 111.03 ms
  IQR:    0.73 ms (111.00 to 111.73)
  9 measurements, 1 runs per measurement, 1 thread

1.2 - Test sizes similar to https://github.com/pytorch/pytorch/blob/master/benchmarks/operator_benchmark/pt/interpolate_test.py

Input tensor: [2, 128, 64, 46]
Input is_contiguous memory_format torch.channels_last: True
Input is_contiguous : False

- Bench upsample linear 2d (1 min_run_time) - downsampling to 32x32
<torch.utils.benchmark.utils.common.Measurement object at 0x7fb5e84a7c40>
upsample_bilinear2d channels_last non-contiguous: [2, 128, 64, 46] -> (32, 32)
1.9.0a0+gite8e570e
  Median: 109.46 us
  IQR:    0.48 us (109.38 to 109.87)
  907 measurements, 10 runs per measurement, 1 thread

- Bench upsample linear 2d (1 min_run_time) - upsampling to 128x128
<torch.utils.benchmark.utils.common.Measurement object at 0x7fb5e84a7c10>
upsample_bilinear2d channels_last non-contiguous: [2, 128, 64, 46] -> (128, 128)
1.9.0a0+gite8e570e
  Median: 1.67 ms
  IQR:    0.03 ms (1.66 to 1.69)
  596 measurements, 1 runs per measurement, 1 thread

1.3 - Test sizes similar to https://github.com/pytorch/pytorch/blob/master/benchmarks/operator_benchmark/pt/interpolate_test.py

Input tensor: [1, 128, 64, 46]
Input is_contiguous memory_format torch.channels_last: True
Input is_contiguous : False

- Bench upsample linear 2d (1 min_run_time) - downsampling to 32x32
<torch.utils.benchmark.utils.common.Measurement object at 0x7fb5e84a7cd0>
upsample_bilinear2d channels_last non-contiguous: [1, 128, 64, 46] -> (32, 32)
1.9.0a0+gite8e570e
  Median: 56.83 us
  IQR:    0.75 us (56.73 to 57.48)
  175 measurements, 100 runs per measurement, 1 thread

- Bench upsample linear 2d (1 min_run_time) - upsampling to 128x128
<torch.utils.benchmark.utils.common.Measurement object at 0x7fb5e84a7dc0>
upsample_bilinear2d channels_last non-contiguous: [1, 128, 64, 46] -> (128, 128)
1.9.0a0+gite8e570e
  Median: 544.52 us
  IQR:    16.37 us (538.45 to 554.83)
  183 measurements, 10 runs per measurement, 1 thread

Input tensor: [1, 3, 500, 500]
Input is_contiguous memory_format torch.channels_last: True
Input is_contiguous : False

- Bench upsample linear 2d (1 min_run_time) - downsampling to 256x256
<torch.utils.benchmark.utils.common.Measurement object at 0x7fb5e84a7e50>
upsample_bilinear2d channels_last non-contiguous: [1, 3, 500, 500] -> (256, 256)
1.9.0a0+gite8e570e
  Median: 1.01 ms
  IQR:    0.06 ms (1.01 to 1.07)
  961 measurements, 1 runs per measurement, 1 thread

- Bench upsample linear 2d (1 min_run_time) - upsampling to 800x800
<torch.utils.benchmark.utils.common.Measurement object at 0x7fb5e84a7070>
upsample_bilinear2d channels_last non-contiguous: [1, 3, 500, 500] -> (800, 800)
1.9.0a0+gite8e570e
  Median: 9.85 ms
  IQR:    0.08 ms (9.81 to 9.90)
  102 measurements, 1 runs per measurement, 1 thread

---- END Benchmark linear 2D ----


---- Benchmark linear 1D ----

---- END Benchmark linear 1D ----


---- Benchmark linear 3D ----

---- END Benchmark linear 3D ----


---- Benchmark nearest 2D ----

---- END Benchmark nearest 2D ----


---- Benchmark nearest 1D ----

---- END Benchmark nearest 1D ----


---- Benchmark nearest 3D ----

---- END Benchmark nearest 3D ----


---- Benchmark cubic 2D ----

---- END Benchmark cubic 2D ----
