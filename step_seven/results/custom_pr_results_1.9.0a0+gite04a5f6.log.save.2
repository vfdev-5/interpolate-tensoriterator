
No CUDA runtime is found, using CUDA_HOME='/usr/local/cuda'
__version__ = 1.9.0a0+gite04a5f6
debug = False
cuda = None
git_version = e04a5f6ea93959e7421ac9f4902e16459d82e07a
hip = None


Uses tests cases:  ['linear:2dcf']
Torch config: PyTorch built with:
  - GCC 9.3
  - C++ Version: 201402
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - CPU capability usage: AVX2
  - Build settings: BUILD_TYPE=Release, CXX_COMPILER=/usr/lib/ccache/c++, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_PYTORCH_QNNPACK -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.9.0, USE_CUDA=0, USE_CUDNN=OFF, USE_EIGEN_FOR_BLAS=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=OFF, USE_MKLDNN=OFF, USE_MPI=OFF, USE_NCCL=OFF, USE_NNPACK=0, USE_OPENMP=ON, 

Num threads: 6


---- Benchmark linear 2D ----

Input tensor: [1, 3, 320, 320]
Input is_contiguous memory_format torch.channels_last: False
Input is_contiguous : True

- Bench upsample linear 2d (15 min_run_time) - downsampling to 256x256
<torch.utils.benchmark.utils.common.Measurement object at 0x7f46a15709a0>
upsample_bilinear2d channels_first contiguous: [1, 3, 320, 320] -> (256, 256)
1.9.0a0+gite04a5f6
  Median: 76.87 us
  IQR:    0.17 us (76.81 to 76.98)
  195 measurements, 1000 runs per measurement, 6 threads

- Bench upsample linear 2d (15 min_run_time) - upsampling to 512x512
<torch.utils.benchmark.utils.common.Measurement object at 0x7f46a1570a90>
upsample_bilinear2d channels_first contiguous: [1, 3, 320, 320] -> (512, 512)
1.9.0a0+gite04a5f6
  Median: 248.90 us
  IQR:    1.33 us (248.47 to 249.80)
  596 measurements, 100 runs per measurement, 6 threads

Input tensor: [1, 3, 320, 320]
Input is_contiguous memory_format torch.channels_last: False
Input is_contiguous : False

- Bench upsample linear 2d (15 min_run_time) - downsampling to 256x256
<torch.utils.benchmark.utils.common.Measurement object at 0x7f46a1570af0>
upsample_bilinear2d channels_first non-contiguous: [1, 3, 320, 320] -> (256, 256)
1.9.0a0+gite04a5f6
  Median: 77.82 us
  IQR:    0.22 us (77.70 to 77.91)
  192 measurements, 1000 runs per measurement, 6 threads

- Bench upsample linear 2d (15 min_run_time) - upsampling to 512x512
<torch.utils.benchmark.utils.common.Measurement object at 0x7f46a1570b50>
upsample_bilinear2d channels_first non-contiguous: [1, 3, 320, 320] -> (512, 512)
1.9.0a0+gite04a5f6
  Median: 249.58 us
  IQR:    0.71 us (249.27 to 249.99)
  599 measurements, 100 runs per measurement, 6 threads

2 - Test size as in https://github.com/mingfeima/op_bench-py

Input tensor: [32, 128, 64, 64]
Input is_contiguous memory_format torch.channels_last: False
Input is_contiguous : True

- Bench upsample linear 2d (15 min_run_time) - downsampling to 32x32
<torch.utils.benchmark.utils.common.Measurement object at 0x7f46a1570940>
upsample_bilinear2d channels_first contiguous: [32, 128, 64, 64] -> (32, 32)
1.9.0a0+gite04a5f6
  Median: 2.33 ms
  IQR:    0.01 ms (2.32 to 2.33)
  641 measurements, 10 runs per measurement, 6 threads

- Bench upsample linear 2d (15 min_run_time) - upsampling to 128x128
<torch.utils.benchmark.utils.common.Measurement object at 0x7f46a1570c40>
upsample_bilinear2d channels_first contiguous: [32, 128, 64, 64] -> (128, 128)
1.9.0a0+gite04a5f6
  Median: 52.96 ms
  IQR:    1.04 ms (52.22 to 53.26)
  284 measurements, 1 runs per measurement, 6 threads

Input tensor: [1, 3, 500, 500]
Input is_contiguous memory_format torch.channels_last: False
Input is_contiguous : True

- Bench upsample linear 2d (15 min_run_time) - downsampling to 256x256
<torch.utils.benchmark.utils.common.Measurement object at 0x7f46a1570df0>
upsample_bilinear2d channels_first contiguous: [1, 3, 500, 500] -> (256, 256)
1.9.0a0+gite04a5f6
  Median: 78.79 us
  IQR:    0.24 us (78.71 to 78.96)
  189 measurements, 1000 runs per measurement, 6 threads

- Bench upsample linear 2d (15 min_run_time) - upsampling to 800x800
<torch.utils.benchmark.utils.common.Measurement object at 0x7f46a1570d90>
upsample_bilinear2d channels_first contiguous: [1, 3, 500, 500] -> (800, 800)
1.9.0a0+gite04a5f6
  Median: 578.95 us
  IQR:    0.99 us (578.50 to 579.48)
  255 measurements, 100 runs per measurement, 6 threads

Input tensor: [1, 3, 500, 500]
Input is_contiguous memory_format torch.channels_last: False
Input is_contiguous : False

- Bench upsample linear 2d (15 min_run_time) - downsampling to 256x256
<torch.utils.benchmark.utils.common.Measurement object at 0x7f46a1570bb0>
upsample_bilinear2d channels_first non-contiguous: [1, 3, 500, 500] -> (256, 256)
1.9.0a0+gite04a5f6
  Median: 79.41 us
  IQR:    0.35 us (79.26 to 79.61)
  188 measurements, 1000 runs per measurement, 6 threads

- Bench upsample linear 2d (15 min_run_time) - upsampling to 800x800
<torch.utils.benchmark.utils.common.Measurement object at 0x7f46a1570d00>
upsample_bilinear2d channels_first non-contiguous: [1, 3, 500, 500] -> (800, 800)
1.9.0a0+gite04a5f6
  Median: 580.67 us
  IQR:    1.61 us (580.07 to 581.68)
  257 measurements, 100 runs per measurement, 6 threads

---- END Benchmark linear 2D ----


---- Benchmark linear 1D ----

---- END Benchmark linear 1D ----


---- Benchmark linear 3D ----

---- END Benchmark linear 3D ----


---- Benchmark nearest 2D ----

---- END Benchmark nearest 2D ----


---- Benchmark nearest 1D ----

---- END Benchmark nearest 1D ----


---- Benchmark nearest 3D ----

---- END Benchmark nearest 3D ----


---- Benchmark cubic 2D ----

---- END Benchmark cubic 2D ----



No CUDA runtime is found, using CUDA_HOME='/usr/local/cuda'
__version__ = 1.9.0a0+gite04a5f6
debug = False
cuda = None
git_version = e04a5f6ea93959e7421ac9f4902e16459d82e07a
hip = None


Uses tests cases:  ['linear:2dcf']
Torch config: PyTorch built with:
  - GCC 9.3
  - C++ Version: 201402
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - CPU capability usage: AVX2
  - Build settings: BUILD_TYPE=Release, CXX_COMPILER=/usr/lib/ccache/c++, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_PYTORCH_QNNPACK -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.9.0, USE_CUDA=0, USE_CUDNN=OFF, USE_EIGEN_FOR_BLAS=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=OFF, USE_MKLDNN=OFF, USE_MPI=OFF, USE_NCCL=OFF, USE_NNPACK=0, USE_OPENMP=ON, 

Num threads: 1


---- Benchmark linear 2D ----

Input tensor: [1, 3, 320, 320]
Input is_contiguous memory_format torch.channels_last: False
Input is_contiguous : True

- Bench upsample linear 2d (15 min_run_time) - downsampling to 256x256
<torch.utils.benchmark.utils.common.Measurement object at 0x7feb8258f970>
upsample_bilinear2d channels_first contiguous: [1, 3, 320, 320] -> (256, 256)
1.9.0a0+gite04a5f6
  Median: 337.93 us
  IQR:    2.06 us (337.33 to 339.39)
  442 measurements, 100 runs per measurement, 1 thread

- Bench upsample linear 2d (15 min_run_time) - upsampling to 512x512
<torch.utils.benchmark.utils.common.Measurement object at 0x7feb8258fa60>
upsample_bilinear2d channels_first contiguous: [1, 3, 320, 320] -> (512, 512)
1.9.0a0+gite04a5f6
  Median: 1.28 ms
  IQR:    0.00 ms (1.28 to 1.28)
  118 measurements, 100 runs per measurement, 1 thread

Input tensor: [1, 3, 320, 320]
Input is_contiguous memory_format torch.channels_last: False
Input is_contiguous : False

- Bench upsample linear 2d (15 min_run_time) - downsampling to 256x256
<torch.utils.benchmark.utils.common.Measurement object at 0x7feb8258fac0>
upsample_bilinear2d channels_first non-contiguous: [1, 3, 320, 320] -> (256, 256)
1.9.0a0+gite04a5f6
  Median: 341.14 us
  IQR:    1.67 us (340.59 to 342.26)
  440 measurements, 100 runs per measurement, 1 thread

- Bench upsample linear 2d (15 min_run_time) - upsampling to 512x512
<torch.utils.benchmark.utils.common.Measurement object at 0x7feb8258f910>
upsample_bilinear2d channels_first non-contiguous: [1, 3, 320, 320] -> (512, 512)
1.9.0a0+gite04a5f6
  Median: 1.28 ms
  IQR:    0.00 ms (1.28 to 1.28)
  117 measurements, 100 runs per measurement, 1 thread

2 - Test size as in https://github.com/mingfeima/op_bench-py

Input tensor: [32, 128, 64, 64]
Input is_contiguous memory_format torch.channels_last: False
Input is_contiguous : True

- Bench upsample linear 2d (15 min_run_time) - downsampling to 32x32
<torch.utils.benchmark.utils.common.Measurement object at 0x7feb8258fb50>
upsample_bilinear2d channels_first contiguous: [32, 128, 64, 64] -> (32, 32)
1.9.0a0+gite04a5f6
  Median: 10.22 ms
  IQR:    0.07 ms (10.19 to 10.26)
  1466 measurements, 1 runs per measurement, 1 thread

- Bench upsample linear 2d (15 min_run_time) - upsampling to 128x128
<torch.utils.benchmark.utils.common.Measurement object at 0x7feb8258fdc0>
upsample_bilinear2d channels_first contiguous: [32, 128, 64, 64] -> (128, 128)
1.9.0a0+gite04a5f6
  Median: 208.82 ms
  IQR:    0.65 ms (208.58 to 209.23)
  72 measurements, 1 runs per measurement, 1 thread

Input tensor: [1, 3, 500, 500]
Input is_contiguous memory_format torch.channels_last: False
Input is_contiguous : True

- Bench upsample linear 2d (15 min_run_time) - downsampling to 256x256
<torch.utils.benchmark.utils.common.Measurement object at 0x7feb8258fe80>
upsample_bilinear2d channels_first contiguous: [1, 3, 500, 500] -> (256, 256)
1.9.0a0+gite04a5f6
  Median: 350.26 us
  IQR:    1.59 us (349.65 to 351.24)
  428 measurements, 100 runs per measurement, 1 thread

- Bench upsample linear 2d (15 min_run_time) - upsampling to 800x800
<torch.utils.benchmark.utils.common.Measurement object at 0x7feb8258ff40>
upsample_bilinear2d channels_first contiguous: [1, 3, 500, 500] -> (800, 800)
1.9.0a0+gite04a5f6
  Median: 3.09 ms
  IQR:    0.01 ms (3.08 to 3.10)
  485 measurements, 10 runs per measurement, 1 thread

Input tensor: [1, 3, 500, 500]
Input is_contiguous memory_format torch.channels_last: False
Input is_contiguous : False

- Bench upsample linear 2d (15 min_run_time) - downsampling to 256x256
<torch.utils.benchmark.utils.common.Measurement object at 0x7feb8258fca0>
upsample_bilinear2d channels_first non-contiguous: [1, 3, 500, 500] -> (256, 256)
1.9.0a0+gite04a5f6
  Median: 352.50 us
  IQR:    1.85 us (351.83 to 353.69)
  425 measurements, 100 runs per measurement, 1 thread

- Bench upsample linear 2d (15 min_run_time) - upsampling to 800x800
<torch.utils.benchmark.utils.common.Measurement object at 0x7feb8258ff70>
upsample_bilinear2d channels_first non-contiguous: [1, 3, 500, 500] -> (800, 800)
1.9.0a0+gite04a5f6
  Median: 3.10 ms
  IQR:    0.02 ms (3.09 to 3.11)
  484 measurements, 10 runs per measurement, 1 thread

---- END Benchmark linear 2D ----


---- Benchmark linear 1D ----

---- END Benchmark linear 1D ----


---- Benchmark linear 3D ----

---- END Benchmark linear 3D ----


---- Benchmark nearest 2D ----

---- END Benchmark nearest 2D ----


---- Benchmark nearest 1D ----

---- END Benchmark nearest 1D ----


---- Benchmark nearest 3D ----

---- END Benchmark nearest 3D ----


---- Benchmark cubic 2D ----

---- END Benchmark cubic 2D ----
